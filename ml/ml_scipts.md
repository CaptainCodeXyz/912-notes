Handscripts when studing Machine Learning
=========================================

> 什么是机器学习？

注意三个点，即E, T, P。

> 监督学习与无监督学习之间的区别？

监督学习是指对于输入的数据，它所对应的输出是已知的。监督学习可以分为两类，即回归问题与分类问题，它们的区别在于输出是否是连续的。具体的例子有房价预测问题（回归问题），判断肿瘤是否是良性（分类问题）。

无监督学习的输入数据之间没有任何区别，每个输入数据都是等价的，并没有事先表明它的状态或者分类信息（比如房价或者恶性肿瘤），而是由机器来分辨不同数据的属性。典型的例子有`聚类问题`（clustering）以及鸡尾酒宴算法。

> 关于深度学习算法的一些思考。

人工神经元算法的设计乃是`线性内核`与`非线性激活`的叠加。根据`线性内核`的不同，可以分为`DNN`，`CNN`，`RNN`，它们分别适用于不同的场景。但是这种建模方法显然是不准确的，片面的，因为实际中的神经元对于各种场合的问题都可以很好的适用。这样，应该存在一种更好的方式来模拟神经元。

人工神经网络的精髓都在于对大脑中的神经元进行模拟。但是我在想神经元并非一定是解决问题的最高效的方法，虽然神经元经过了几十亿年的进化与自然选择，但它未必是解决现实问题的最优解，可能只是一个局部最优而已，alphaGo的例子就说明了这一点——人类数千年形成的围棋算法实际上只是局部最优解。

另一方面，让计算机模拟人脑也未必就是最好的方法。因此我在想，有没有可能跳出现有神经元的桎梏，开创出一个更优化的算法，这样说不定还可以反过来对人类的神经元进行改造。

> 梯度下降法存在的问题。

首先是学习率(learning rate)的选择。如果$\alpha$太小，则需要多次迭代才能找到局部最优解，需要较长的学习时间；而如果$\alpha$太大，则可能直越过最低点，导致无法收敛，甚至发散。

因此$\alpha$的选择，最好是选择可以使代价函数收敛的最大的$\alpha$，为了找到这样一个$\alpha$，可以作出代价函数-迭代次数的关系图。从理论上来将，如果$\alpha$取得足够小，则每一次迭代代价函数都会减小。因此，如果代价函数呈现出其他的趋势，则往往说明是$\alpha$取得太大了。

需要指出的是，$\alpha$过大时，也可能会出现收敛速度慢的现象。

此外，显而易见的是，梯度下降法只能找到局部最优解，而非全局最优解。实际上，梯度下降法找到的解取决于初始位置的选择。然而，对于线性回归（linear regression)问题，则不存在这个问题，因为线性回归问题的代价函数是一个凸函数(convex function)，即它只有一个极值点，该极值点就是它的全局最优解，因此使用梯度下降算法总是可以得到唯一的最优解。

> 梯度下降法的深入讨论。

对于多元的线性回归问题，如果不同的特征取值范围差别很大，比如$0 < x_1 < 1$，$0 < x_2 < 1000$，两者的取值范围查了1000倍。在使用梯度下降法时，参数$\theta_2$的变化量也将是$\theta_1$的1000倍，这将导致损失函数等高线图呈现扁平的椭圆状，梯度下降路径相对取值范围更大的特征对应的参数来回波动，导致收敛速度缓慢。但是关于这个的数学推导我仍然存在问题。

为了解决上面的问题，需要对取值相差比较大的特征进行特征缩放(feature scaling)，使它们的取值都在1的附近。这样得到的等高线图就接近于圆形，收敛速度就要快多了。

此外还有一个方法是使这些特征的平均值都在0附近，相对于对特征进行了规范化。

> 在线性回归问题中，是通过平方损失函数(square error function)作为损失函数，来对参数进行优化的。老师说这样得到的是一条可能性最大的直线，是否可以用最大似然估计来解释这一点呢？

后来的总结中给出了数学推导。

> 多元线性回归(multivariate linear regression)的梯度下降法与规范方程法(normal equation)的一些问题。

不明白规范方程法正确性的证明，以及通过多元极值求得的结果与规范方程法是否一致？

用平方损失函数，利用多元极值求得的$\theta$与求解矩阵方程$Y = X\theta$所得到的结果一致，即$\theta = (X^X)^{-1}X^TY$，不得不让人思考两者是否有什么内在的联系？

规范方程法伪逆(pseudo-inversion)的数学推导；为什么求逆操作的时间复杂度是`O(n^3)`，其中`n`表示特征的数量。

为什么梯度下降法的时间复杂度是`O(kn^2)`，k是什么含义。

> 为什么是平方损失函数？
