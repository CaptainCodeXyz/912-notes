数据结构与算法第一章知识总结
=========================

## 为什么需要数据结构和算法

讨论这个问题之前，先想想究竟什么是计算机，又什么是算法。

_Computer science should be called computing science, for the same reason why surgery is not called knife science.
-- E. Dijkstra_

## 几个实例

+ 绳索计算机以及计算垂直线的算法
+ 尺规计算机以及计算三等分点的算法。
+ 现代电子计算机以及冒泡排序的算法。

## 什么是算法

上面几个例子其实并没有本质的区别，几千年前的人们就开始研究了各种各样的算法，现代人还在重复这个研究工作。

从上面的例子中，我们可以总结出算法的基本概念：

+ 所谓计算，本质上是对信息处理的过程。对输入的数据按照机械的步骤，执行得出结果的过程。
+ 所谓计算模型，如上面的绳索和尺规，就是计算机，即信息处理的工具。
+ 这样的话，算法就是在特定的计算模型下，旨在解决问题的指令序列
	- 输入
	- 输出
	- 正确性
	- 确定性
	- 可行性
	- 有穷性: 如Hailstone问题，尚未证实其有穷性
	- ...

评价一个算法，常常具有上面这许多因素。在算法正确的基础上，我们会比较关注一个算法的代价，即它运行的时间与空间。

## 算法的评价

_Algorithm + Data Structure = Programs // N.Wirth, 1976_

_(Algorithm + Data Structure) x Efficiency = Computation // Pro Deng_

对于求解同一个问题，往往会存在许多不同的算法。问题在于，应该如何评价这些算法的优劣呢？

### 度量的基准

_To measure is to know. If you cannot measure it, you cannot improve it
-- Lord Kelvin_

考虑我们要评价两个不同算法的优劣，一个很自然的思想是实验测量，通过测量这两个算法在同一问题实例(instance)P的情况下，两个算法的运行代价。即

$$T_A(P) = the\ cost\ of\ algorithm\ A\ to\ solve\ instance\ P$$

可是，这样的测量真的有意义吗？

很明显，上面的方法存在下面的问题。针对某个问题实例的测量，并不能反映算法在实际运行时的性能。因为实际运行时的问题实例有很多，不同实例之间算法的性能很难说有相关性。

那好，我们对不同的问题实例进行抽象。根据经验，一般的算法的运行代价和问题的规模是相关的。一般说来，问题的规模越大，算法运行的代价越大(当然也有反例，如Hailstone)。这样，我们就可以把基于问题实例P的测量，转化为基于一系列规模为n的问题实例P的测量，即

$$ T_A(n) = the\ cost\ of\ algorithm\ to\ solve\ instances\ of\ scale\ n $$

有下面两种方案：

+ 最坏情况下的运行代价
+ 平均情况下的运行代价

实际上，多数情况下，我们都是关注最坏情况下算法的运行代价。

### 理想模型

有了上面的讨论后，终于可以评价算法的优劣的吧？其实还不行。因为实验测量的方法还会受到外界因素的影响。

例如绳索计算机以及尺规计算机，其运行效率与操作人员的熟练程度，当天状态是息息相关的。现代计算机也是一样，即使使用同一台机器运行两个算法，也会由于进程的调度，硬盘的读写情况不同而多少有所差异。所以，实验测量的方式是可以的，但是是不准确的。

由上面的讨论，我们需要的是理想的平台或是模型，使我们可以不再依赖于上面的各种不确定因素，从而直接准确地描述并测量算法。

+ 图灵机TM(Turning Machine)
	- 有一条纸带(tape), 上面均匀地划分了小格，格子里面是字符，默认为'#'
	- 字符(alphabet)的个数是有限的
	- 存在一个头指针(Head),指向纸带上的某一个单元格，可以读写其中的字符
	- 头指针存在状态(State), 也是TM的状态。每一步都可以改变自己的状态
	- 每一步会执行一个传递函数`Transition_Function(q, c; d, L/R, p)`: 当前状态为q且当前字符为c，将当前字符改写成d， 当前状态改写成p，并且向左L或向右R移动。一旦转入特定状态'h'(for halt)，则进入停机。
	- 实例：将二进制非负整数加一

+ Random Access Machine
	- 具有一些顺序编号的寄存器R[0], R[1], R[2]...总数没有限制
	- 具有一些基本操作，都只需要花费常数时间

	```
	R[i] <- c     		R[i] <- R[R[j]]			R[i] <- R[j] + R[k]
	R[i] <- R[j]		R[R[i]] <- R[j]			R[i] <- R[j] - R[k]
	IF R[i] = 0 GOTO l 	IF R[i] > 0 GOTO l 		GOTO l 		STOP
	```

	- 实例：floor向下取整的除法(就跟汇编似的)

可以看到，TM模型和RAM模型一样，都是把运算抽象成了各个基本操作的叠加。而这些基本操作的运行时间是固定的，平台无关的。这样我们就可以独立于具体的平台，对算法的效率做出可信的比较与评价。

由于每步基本操作的运行时间是固定的，因此我们可以使用算法执行所需要的基本操作的次数来评价一个算法。这样

$$T(n) = number\ of\ basic\ operations\ to\ solve\ a\ problem\ of\ scale\ n$$

### big O notation

前面说到通过建立的理想模型，我们可以把算法运行的时间，转化成在理想模型上运行的基本操作的次数。从而我们已经可以对不同的算法进行比较。这样的比较绝对是严谨的，只是在操作上还存在一些问题。

容易设想到，不同的算法针对不同规模输入的数据，其表现也不会相同。一些算法在小规模输入时表现良好，另一些则恰恰相反，在大规模输入时表现突出。这对应与两个算法的T(n)并不是严格的大于或者小于关系，而是一个此消彼长的过程。这种情况对于我们比较算法的优劣是不利的，因此有必要采取一些别的措施。

在评价算法的效率时，其实对于小规模的问题，我们往往不太关心它的效率，这是因为此时不同的算法的差异并不明显。因此，我们往往更关注于更大规模问题的效率。这种着眼长远，更注重时间复杂度的总体变化趋势的分析方法，即渐进分析(asymptotic analysis)。

存在不同的渐进分析方法。回忆我们之间提到，我们往往是评价一个算法在最坏情况下的效率，这里引入大O记号(big O notation),其定义如下：

_若存在函数f(n)和正的常数c，使得在渐进的条件(n >> 2)下，T(n) <= c·f(n)，则可以认为f(n)给出了T(n)增长速度的一个上界(最坏情况)，记T(n) = O(f(n))_

同时，根据定义，可以给出大O记号的几个性质:
+ 对于任意常数 c > 0, O(f(n)) = O(c·f(n))
+ 对于任意常数 a > b > 0, O(n^a + n^b) = O(n^a)

要注意的是，性质2表面上是忽略了多项式中的低次项，本质上，是在大O记号的基础上进行了放大，然后忽略掉常数项

$$n^a + n^b <= n^a + n^a = 2 * n^a = O(n^a)$$

在计算大O记号时，可以直接忽略低次项的原因也在于此。

### Other notations

上面也说了，大O记号表示的是最坏情况下算法在时间复杂度上的增长趋势。除此以外，还存在在最好情况下，以及平均情况下的时间估计。

#### big $\Omega$ notation

big $\Omega$ notation是标志了算法运行时间的下届，即最好情况，其定义如下:

_若存在函数f(n)和正的常数c，使得在渐进的条件(n >> 2)下，T(n) >= c·f(n)，则可以认为f(n)给出了T(n)增长速度的一个下届(最好情况)，记T(n) = $\Omega$(f(n))_

#### big $\Theta$ notation

big $\Theta$ notation 是标志算法运行时间的平均情况，它也具有相似的定义:

_若存在函数f(n)和正的常数c1和c2，使得在渐进的条件(n >> 2)下，c1·f(n) < =T(n) <= c2·f(n)，则可以认为f(n)给出了T(n)增长速度的平均情况，记T(n) = $\Theta$(f(n))_
